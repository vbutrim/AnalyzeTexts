{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.txt', sep='\\t', header=-1, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_marks = list()\n",
    "\n",
    "for i in xrange(len(data[0])):\n",
    "    if (data[0][i] == 'ham'):\n",
    "        list_marks.append(0)\n",
    "    else:\n",
    "        list_marks.append(1)\n",
    "        \n",
    "list_phrases = data[1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n",
      "<type 'list'>\n",
      "\n",
      "5572\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print len(list_marks)\n",
    "print type(list_marks)\n",
    "print\n",
    "print len(list_phrases)\n",
    "print type(list_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction\n",
    "from sklearn import svm\n",
    "\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "features = count_vectorizer.fit_transform(list_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97559224694903091"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, list_marks)\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90196078  0.87037037  0.99099099  0.98181818  0.90384615  0.93577982\n",
      "  0.92307692  0.94230769  0.96226415  0.97196262]\n",
      "0.9384377681\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print np.average(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB', 'FreeMsg: Txt: claim your reward of3 hours talk time', 'Have you visited the last lecture on physics?', 'Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$', 'Only 99$']\n"
     ]
    }
   ],
   "source": [
    "X1_test = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "           \"FreeMsg: Txt: claim your reward of3 hours talk time\",\n",
    "           \"Have you visited the last lecture on physics?\",\n",
    "           \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "           \"Only 99$\"]\n",
    "print X1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(features, list_marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Прогнозы классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print logReg.predict(count_vectorizer.transform(X1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diffParamsForCountVectorizer(my_ngram_range):\n",
    "    my_count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=my_ngram_range)\n",
    "    my_features = my_count_vectorizer.fit_transform(list_phrases)\n",
    "    \n",
    "    my_logReg = LogisticRegression()\n",
    "    my_scores = cross_val_score(my_logReg, my_features, list_marks, cv=10, scoring='f1_macro')\n",
    "    \n",
    "    return np.average(my_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Значения f1-меры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 0.85 0.96\n"
     ]
    }
   ],
   "source": [
    "print round(diffParamsForCountVectorizer((2, 2)), 2), round(diffParamsForCountVectorizer((3, 3)), 2), round(diffParamsForCountVectorizer((1, 3)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def diffParamsForCountVectorizerWithMulti(my_ngram_range):\n",
    "    my_count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=my_ngram_range)\n",
    "    my_features = my_count_vectorizer.fit_transform(list_phrases)\n",
    "    \n",
    "    my_Multinominal = MultinomialNB()\n",
    "    my_scores = cross_val_score(my_Multinominal, my_features, list_marks, cv=10, scoring='f1_macro')\n",
    "    \n",
    "    return np.average(my_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный Байес действительно страдает от нехватки статистики по биаграммам и триаграммам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78 0.52 0.93\n"
     ]
    }
   ],
   "source": [
    "print round(diffParamsForCountVectorizerWithMulti((2, 2)), 2), round(diffParamsForCountVectorizerWithMulti((3, 3)), 2), round(diffParamsForCountVectorizerWithMulti((1, 3)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916614907888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "my_features = tfidf_vectorizer.fit_transform(list_phrases)\n",
    "my_logReg = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(my_logReg, my_features, list_marks, cv=10, scoring='f1_macro')\n",
    "\n",
    "print np.average(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество понизилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    "\n",
    "Все вместе: биаграммы, триаграммы, униграммы - работает хорошо.\n",
    "LogisticRegression лучше MultinominalNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
